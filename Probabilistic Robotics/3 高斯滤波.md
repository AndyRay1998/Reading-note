[[Probabilistic Robotics]]

```toc
```

### 3.1 引言
- 对很多全局估计问题，由千许多很不同的假设存在，每一个假设都形成其自己的后验模式，因此高斯后验匹配性并不好。
- 后验以小的不确定性聚集在真实状态周围
- 高斯滤波中参数均值和方差称为矩参数(moments parameterization)
- 均值和方差是概率分布的一阶矩和二阶矩


### 3.2 卡尔曼滤波
#### 3. 2. 1 线性高斯系统
- 线性高斯(linear Gaussian)![[Pasted image 20220616161847.png]]
- 带入多元![[Pasted image 20220616162406.png]]
- 测量概率带有高斯方差![[Pasted image 20220616162501.png]]
- 初始置信度为正态分布![[Pasted image 20220616162517.png]]

#### 3.2.2 卡尔曼滤波算法
- ![[Pasted image 20220616162740.png]]
- 2-3行预测，4-6更新

#### 3.2.3 例证
- 中文书p50


#### 3.2.4 卡尔曼滤波的数学推导
- 预测 2-3行
		- ![[Pasted image 20220616163331.png]]
		- 带入高斯形式![[Pasted image 20220616163547.png]] ![[Pasted image 20220616164307.png]]


### 3.3 扩展卡尔曼滤波
#### 3.3.1 为什么要线性化
- 扩展卡尔曼滤波(Extended Kalman Filter, EKF) , 放宽了其中的一个假设：线性化假设。这里假设状态转移概率和测量概率分别由非线性(nonlinear) 函数g 和h 控制：![[Pasted image 20220616171054.png]]
- 对于任意函数g和h, 置信度不再是一个高斯分布。事实上，准确地实现置信度更新对于非线性函数g和h通常是不可能的，贝叶斯滤波不存在闭式解。
- EKF 的目标就从计算精确的后验概率转变为有效地估计其均值和方差

#### 3.3.2 通过泰勒展开的线性化
- EKF 通过一个与h相切的线性函数来近似h, 从而保持后验置信度的高斯特性![[Pasted image 20220616171910.png]]
- 线性化优点在于效率，对比蒙特卡洛近似
- 状态方程：一阶泰勒展开![[Pasted image 20220616172321.png]]
- 写成高斯形式![[Pasted image 20220616172537.png]]
- 测量方程：在预测均值处展开![[Pasted image 20220616172618.png]]
- 写成高斯![[Pasted image 20220616172857.png]]

#### 3.3.3 扩展卡尔曼滤波算法
- update rule![[Pasted image 20220616173308.png]]
- 对比KF![[Pasted image 20220616173337.png]]

#### 3. 3. 4 扩展卡尔曼滤波的数学推导
- 预测![[Pasted image 20220616173805.png]]


#### 3.3.5 实际考虑
- $O(k^{2.4}+n^2)$
- EKF 较高的计算效率归功于用多元高斯分布表示置信度
- EKF 已成功用于解决大量违反基本假设的状态估计问题
- 在许多实际问题中，高斯分布是鲁棒估计的
- EKF 使用线性泰勒展开对状态变换和测量进行近似，所以受到了很大局限
- EKF 所应用的线性近似是否具有优势主要取决千两个因素：被近似的局部非线性化程度和不确定程度


### 3.4 无迹卡尔曼滤波 (unscented)
- 加权统计线性回归过程实现随机线性化

#### 3. 4. 1 通过无迹变换实现线性化
- 从n维获取2n+1个加权点，经过g变换，由线性化的高斯函数从加权点获得近似高斯函数![[Pasted image 20220617210337.png]]
- 无迹变换与泰勒级数展开的前两项精度相同，但EKF 只取了前一项

#### 3.4.2 无迹卡尔曼滤波算法
![[Pasted image 20220617211221.png]]
- 对于纯线性系统，由UKF 产生的估计与由卡尔曼滤波产生的估计是相同的。对于非线性系统， UKF 的结果与EKF 的结果相同或者比后者要好，EKF 的改进依赖非线性和先验状态不确定性的范围。在许多实际应用中， EKF和UKF 之间的差异不大。
- UKF不需要计算雅可比矩阵，被认为是免求导滤波器。
- 如果置信度是高度非高斯的，那么UKF 表示就具有很大局限性，滤波实现会很差。


### 3.5 信息滤波
- 卡尔曼滤波的对偶算法 信息滤波information filter, IF
- KF的高斯分布有矩表示，IF用正则参数表示，正则参数和矩参数经常被认为是对偶的

#### 3. 5.1 正则参数 canonical parameterization
- 信息矩阵information matrix $\Omega=\Sigma^{-1}$
- 信息向量information vector $\xi=\Sigma^{-1} \mu$
- 多元高斯分布，将不依赖x的项提出，得到![[Pasted image 20220617212238.png]] ![[Pasted image 20220617212300.png]]
- 取负对数，为x的二次型函数![[Pasted image 20220617212340.png]]
- 取一阶导，得到-logp(x)的均值![[Pasted image 20220617212443.png]]
- 由矩阵$\Omega$加权的二次距离叫作马氏距离(Mahalanobis distance)

#### 3.5.2 信息滤波算法
- 回顾线性高斯方程![[Pasted image 20220617213230.png]] ![[Pasted image 20220617213248.png]]
- update rule![[Pasted image 20220617213302.png]]

#### 3. 5. 3 信息滤波的数学推导
- 预测
		- 带入信息矩阵和信息向量公式即可
- 更新
		- 正则形式高斯分布![[Pasted image 20220617214029.png]]
		- 重新排列指数项![[Pasted image 20220617214041.png]]
		- 合并方框内![[Pasted image 20220617214056.png]]

#### 3.5.4 扩展信息滤波算法 Extended Information Filter, EIF
- 类似EKF![[Pasted image 20220617214206.png]]
- update rule![[Pasted image 20220617214231.png]]

#### 3.5.5 扩展信息滤波的数学推导
略

#### 3.5.6 实际考虑
- IF的优点
		- 在IF 中表示全局不确定性是很简单的：简单地设置$\Omega=0$ 。当使用矩参数时，这样的全局不确定性意味着无限大的方差
		- IF 及其几种扩展方法使机器人能够进行信息整合，而不是立即将信息转化成概率。这在涉及成百甚至更多量的复杂估计问题时具有很大的优势
		- 它对多机器人间题的自然适应性。多机器人传感器融合使用贝叶斯准则，(3.78)中正则参数将概率用对数形式表达，可以让贝叶斯准则变成加法，从而可以用完全分散任意时延任意顺序进行信息融合。
		- IF在多机器人系统的应用仍有很多未开发部分
- IF的缺点
		- 涉及信息矩阵求逆太多，在高维领域不友好